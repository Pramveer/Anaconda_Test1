{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARK HOME ==>   D:\\Spark1.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Configure the environment\n",
    "#if 'SPARK_HOME' not in os.environ:\n",
    "#    os.environ['SPARK_HOME'] = '/srv/spark'\n",
    "\n",
    "# Create a variable for our root path\n",
    "SPARK_HOME = os.environ['SPARK_HOME']\n",
    "\n",
    "print(\"SPARK HOME ==>  \",SPARK_HOME);\n",
    "\n",
    "# Add the PySpark/py4j to the Python Path\n",
    "sys.path.insert(0, os.path.join(SPARK_HOME, \"python\", \"lib\"))\n",
    "sys.path.insert(0, os.path.join(SPARK_HOME, \"python\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "#conf = SparkConf().setAppName(\"myapp\").setMaster(\"local[0]\");\n",
    "conf = SparkConf().setAppName(\"MyApp\").setMaster(\"local\");\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pyspark  \n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.tree import DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data_rdd = sc.textFile(\"../datasets/titanic.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total File Size ==>   1317\n"
     ]
    }
   ],
   "source": [
    "print(\"Total File Size ==>  \",raw_data_rdd.count());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets take only 500 data points from the dataset instead of pulling all the dataset\n",
    "\n",
    "raw_data_rdd.take(500);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove the header from the csv file\n",
    "\n",
    "csv_header = raw_data_rdd.first();\n",
    "data_rdd = raw_data_rdd.filter(lambda line: line != csv_header);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#take sample of data from the dataset\n",
    "\n",
    "data_rdd.takeSample(False, 500, 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to create labeled point data vectors\n",
    "\n",
    "def row_to_labeled_point(line):\n",
    "    '''\n",
    "    Builds a LabelPoint consisting of:\n",
    "    \n",
    "    survival (truth): 0=no, 1=yes\n",
    "    ticket class: 0=1st class, 1=2nd class, 2=3rd class\n",
    "    age group: 0=child, 1=adults\n",
    "    gender: 0=man, 1=woman\n",
    "    '''\n",
    "    passenger_id, klass, age, sex, survived = [segs.strip('\"') for segs in line.split(',')]\n",
    "    klass = int(klass[0]) - 1\n",
    "    \n",
    "    if (age not in ['adults', 'child'] or \n",
    "        sex not in ['man', 'women'] or\n",
    "        survived not in ['yes', 'no']):\n",
    "        raise RuntimeError('unknown value')\n",
    "    \n",
    "    features = [\n",
    "        klass,\n",
    "        (1 if age == 'adults' else 0),\n",
    "        (1 if sex == 'women' else 0)\n",
    "    ]\n",
    "    return LabeledPoint(1 if survived == 'yes' else 0, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#map the labeled point the dataset\n",
    "labeled_points_rdd = data_rdd.map(row_to_labeled_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labeled_points_rdd.takeSample(False,10, 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the dataset for training(70%) & testing(30%)\n",
    "training_rdd, test_rdd = labeled_points_rdd.randomSplit([0.7, 0.3], seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count ==>  922\n",
      "Test Dataset Count ==>  394\n"
     ]
    }
   ],
   "source": [
    "training_count = training_rdd.count()\n",
    "test_count = test_rdd.count()\n",
    "\n",
    "print(\"Training Dataset Count ==> \",training_count);\n",
    "print(\"Test Dataset Count ==> \",test_count);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train and test a decision tree classifier\n",
    "model = DecisionTree.trainClassifier(training_rdd, \n",
    "                                     numClasses=2, \n",
    "                                     categoricalFeaturesInfo={\n",
    "                                        0: 3,\n",
    "                                        1: 2,\n",
    "                                        2: 2\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions outcomes\n",
    "predictions_rdd = model.predict(test_rdd.map(lambda x: x.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#truth outcome for each passenger in the test set\n",
    "truth_and_predictions_rdd = test_rdd.map(lambda lp: lp.label).zip(predictions_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy =>  0.8020304568527918\n",
      "DecisionTreeModel classifier of depth 4 with 21 nodes\n",
      "  If (feature 2 in {0.0})\n",
      "   If (feature 1 in {0.0})\n",
      "    If (feature 0 in {0.0,1.0})\n",
      "     Predict: 1.0\n",
      "    Else (feature 0 not in {0.0,1.0})\n",
      "     Predict: 0.0\n",
      "   Else (feature 1 not in {0.0})\n",
      "    If (feature 0 in {1.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 0 not in {1.0})\n",
      "     If (feature 0 in {0.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 0 not in {0.0})\n",
      "      Predict: 0.0\n",
      "  Else (feature 2 not in {0.0})\n",
      "   If (feature 0 in {2.0})\n",
      "    If (feature 1 in {0.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 1 not in {0.0})\n",
      "     Predict: 0.0\n",
      "   Else (feature 0 not in {2.0})\n",
      "    If (feature 0 in {1.0})\n",
      "     If (feature 1 in {0.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 1 not in {0.0})\n",
      "      Predict: 1.0\n",
      "    Else (feature 0 not in {1.0})\n",
      "     If (feature 1 in {0.0})\n",
      "      Predict: 1.0\n",
      "     Else (feature 1 not in {0.0})\n",
      "      Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = truth_and_predictions_rdd.filter(lambda v_p: v_p[0] == v_p[1]).count() / float(test_count)\n",
    "print('Model Accuracy => ', accuracy);\n",
    "print(model.toDebugString());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train and test a logistic regression classifier\n",
    "logit_model = LogisticRegressionWithSGD.train(training_rdd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_rdd = logit_model.predict(test_rdd.map(lambda x: x.features));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_and_predictions_rdd = test_rdd.map(lambda lp: lp.label).zip(predictions_rdd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit Model Accuracy =>  0.7918781725888325\n"
     ]
    }
   ],
   "source": [
    "accuracy = labels_and_predictions_rdd.filter(lambda v_p: v_p[0] == v_p[1]).count() / float(test_count)\n",
    "print('Logit Model Accuracy => ', accuracy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit Model Intercept =>  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Logit Model Intercept => \",logit_model.intercept);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit Model Weights =>  [-0.626119570298,-0.154014997299,1.23177368167]\n"
     ]
    }
   ],
   "source": [
    "print(\"Logit Model Weights => \",logit_model.weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shutdown spark istance\n",
    "sc.stop();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
